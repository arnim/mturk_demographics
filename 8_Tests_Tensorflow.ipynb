{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Hf1JNmQrClhq"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hordFQNCClhu"
   },
   "outputs": [],
   "source": [
    "# By uncommenting the lines below we allow for \"eager execution\"\n",
    "# which is useful for debugging, as every command is executed immediately\n",
    "#\n",
    "import tensorflow.contrib.eager as tfe\n",
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1518236469827,
     "user": {
      "displayName": "Panos Ipeirotis",
      "photoUrl": "//lh4.googleusercontent.com/-dIWj8iHQSKU/AAAAAAAAAAI/AAAAAAAC_ik/-lah8-gvNJM/s50-c-k-no/photo.jpg",
      "userId": "103666871486129948108"
     },
     "user_tz": 480
    },
    "id": "cyxaSZo2Clh6",
    "outputId": "3d5368a5-f019-4166-9f04-5cfa389fe187"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=0, shape=(4,), dtype=int32, numpy=array([0, 1, 0, 4], dtype=int32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_time_seen = [0, 1, 0, 4]\n",
    "f = tf.constant(first_time_seen, name=\"first_time_seen\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1518236470367,
     "user": {
      "displayName": "Panos Ipeirotis",
      "photoUrl": "//lh4.googleusercontent.com/-dIWj8iHQSKU/AAAAAAAAAAI/AAAAAAAC_ik/-lah8-gvNJM/s50-c-k-no/photo.jpg",
      "userId": "103666871486129948108"
     },
     "user_tz": 480
    },
    "id": "Jr5Oy0aTClh9",
    "outputId": "7f7d8bf6-ff17-41ba-e35c-edf29acca563"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2, shape=(4,), dtype=int32, numpy=array([0, 2, 4, 4], dtype=int32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_time_seen = [0, 2, 4, 4]\n",
    "l = tf.constant(last_time_seen, name=\"last_time_seen\")\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1518236470915,
     "user": {
      "displayName": "Panos Ipeirotis",
      "photoUrl": "//lh4.googleusercontent.com/-dIWj8iHQSKU/AAAAAAAAAAI/AAAAAAAC_ik/-lah8-gvNJM/s50-c-k-no/photo.jpg",
      "userId": "103666871486129948108"
     },
     "user_tz": 480
    },
    "id": "feCkLMKoCliA",
    "outputId": "202b8067-f9be-4bcf-8ac6-a30453f9f29a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4, shape=(4,), dtype=float64, numpy=array([1., 2., 5., 1.])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = [1, 2, 5, 1]\n",
    "u = tf.constant(count, name=\"count\", dtype=tf.float64)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = len(count)\n",
    "K = max(last_time_seen)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of unseen workers.\n",
    "Uh  = tf.get_variable( dtype=tf.float64, shape=(), name = \"u_hidden\", initializer=tf.constant_initializer(10) ) \n",
    "U = tf.square(Uh, name=\"unseen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KqgVEOrwCliD"
   },
   "outputs": [],
   "source": [
    "# Propensity distribution parametes (propensity ~ Beta(a,b))\n",
    "a = tf.get_variable(\"pronensity_alpha\", shape=(), dtype=tf.float64, initializer=tf.constant_initializer(np.sqrt(2))  )\n",
    "a = tf.square(a)\n",
    "b = tf.get_variable(\"pronensity_beta\",  shape=(), dtype=tf.float64, initializer=tf.constant_initializer(np.sqrt(2)) )\n",
    "b = tf.square(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nvColmPLCliL"
   },
   "outputs": [],
   "source": [
    "# Arrival and departure rates\n",
    "# In our likelihood lambda_s and mu_q are treated as probabilities and cannot be negative\n",
    "# To ensure non-negativity, and put the values between 0..1, we will start with two unconstrained\n",
    "# parameters, which we will then convert into a 0..1 variable using a tanh. \n",
    "# Then, we can use the standard unconstrained optimization on lh and mh\n",
    "# We initialize variables to log(1/(K-1)) to out all variables to be \n",
    "lh = tf.get_variable(\"arrivals_latent\",   [K], dtype=tf.float64, initializer=tf.constant_initializer(np.log(1/(K-1))))\n",
    "mh = tf.get_variable(\"departures_latent\", [K], dtype=tf.float64, initializer=tf.constant_initializer(np.log(1/(K-1))))\n",
    "\n",
    "# Ensures the values lambda and mu are positive and between 0 and 1\n",
    "lmd = tf.sigmoid(lh, name='arrivals')\n",
    "mu  = tf.sigmoid(mh, name='departures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=51, shape=(5,), dtype=float64, numpy=array([0.2, 0.2, 0.2, 0.2, 0.2])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=53, shape=(5,), dtype=float64, numpy=array([0.2, 0.2, 0.2, 0.2, 0.2])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing the implementation of likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdpM1w9UCliN"
   },
   "source": [
    "### $L_i = \\sum_{s=1}^{f_i} \\sum_{q=l_i}^K \\lambda_s \\cdot  \\left( \\prod_{v=s}^{q-1} \\left(1 - \\mu_v\\right) \\right) \\cdot \\mu_q \\cdot  R_i(s,q) $\n",
    "\n",
    "###  $R_i(s,q) = f(u_i|n,\\alpha,\\beta) = \\frac{\\Gamma(n+1)}{\\Gamma(u_i+1)\\Gamma(n-u_i+1)} \\frac{\\Gamma(u_i+\\alpha)\\Gamma(n-u_i+\\beta)}{\\Gamma(n+\\alpha+\\beta)}                        \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}$\n",
    "\n",
    "with $n = q-s$ (or $n = q-s+1$?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the Birth-Death probability for each worker\n",
    "\n",
    "We will start by computing the probability that a given worker arrived at time $s$ and departed at time $q$.\n",
    "\n",
    "We will store the result at a $I \\times K \\times K$ tensor `LD_isq`. The values in this tensor will be the product $\\lambda_s \\cdot  \\left( \\prod_{v=s}^{q-1} \\left(1 - \\mu_v\\right) \\right) \\cdot \\mu_q$, and will be zero for infeasible combinations of $s$ and $q$. For example, if a user was first seen at time $f$, any arrival time $s>f$ is infeasible. Similarly, for departure times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TMO41i-pCliU"
   },
   "outputs": [],
   "source": [
    "# To allow for the sums of variable length s .. f_i and l_i...K, we will use binary masks\n",
    "# This allows the products to be defined over a constant set of dimensions (ie. 1..K instead of 1..fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=80, shape=(4, 5, 5), dtype=float64, numpy=\n",
       "array([[[1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.]]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create masks using the values from f so that for each worker we add the lamda_s until the first appearance\n",
    "s_mask = tf.sequence_mask(f+1, K)\n",
    "s_mask = tf.cast(s_mask, tf.float64)\n",
    "\n",
    "# Create masks using the values from l so that for each worker we add the mu_q from the first appearance until the end\n",
    "q_mask = ~tf.sequence_mask(l, K)\n",
    "q_mask = tf.cast(q_mask, tf.float64)\n",
    "\n",
    "# This is a mask that only allows feasible combinations of s and q for a given worker i\n",
    "# It is effectively the outer product of the s_mask and q_mask, for each worker\n",
    "i_mask = tf.einsum(\"is,iq->isq\", s_mask,q_mask)\n",
    "i_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1518236476549,
     "user": {
      "displayName": "Panos Ipeirotis",
      "photoUrl": "//lh4.googleusercontent.com/-dIWj8iHQSKU/AAAAAAAAAAI/AAAAAAAC_ik/-lah8-gvNJM/s50-c-k-no/photo.jpg",
      "userId": "103666871486129948108"
     },
     "user_tz": 480
    },
    "id": "jMS_tsCMClie",
    "outputId": "91538f46-fab5-463b-9e11-a2912f4f33fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=82, shape=(5, 5, 5), dtype=float64, numpy=\n",
       "array([[[0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 1., 0., 0.],\n",
       "        [0., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 1., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And create a mask to calculate the product of 1-mu_v\n",
    "# It has as 1 the mu's that need to be in the product, \n",
    "# for arrival at s and departure at q\n",
    "v = np.zeros([K,K,K])\n",
    "for s in np.arange(K):\n",
    "    for q in np.arange(s,K):\n",
    "        c1 = np.zeros(s)\n",
    "        c2 = np.ones(q-s)\n",
    "        c3 = np.zeros(K-q)\n",
    "        v[s,q]= np.concatenate((c1, c2, c3))\n",
    "v_mask = tf.constant(v)\n",
    "v_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=88, shape=(5, 5), dtype=float64, numpy=\n",
       "array([[1.    , 0.8   , 0.64  , 0.512 , 0.4096],\n",
       "       [1.    , 1.    , 0.8   , 0.64  , 0.512 ],\n",
       "       [1.    , 1.    , 1.    , 0.8   , 0.64  ],\n",
       "       [1.    , 1.    , 1.    , 1.    , 0.8   ],\n",
       "       [1.    , 1.    , 1.    , 1.    , 1.    ]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating m_v(s,q) = Prod_s^q-1 mu_v\n",
    "# mu_v[s,q]: Probability of surviving from period s to period q-1\n",
    "# if q-1<s then probability is 1\n",
    "mu_v = tf.pow(1-mu, v_mask)\n",
    "mu_v = tf.reduce_prod(mu_v, axis=2)\n",
    "mu_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=103, shape=(5, 5), dtype=float64, numpy=\n",
       "array([[0.04    , 0.032   , 0.0256  , 0.02048 , 0.016384],\n",
       "       [0.04    , 0.04    , 0.032   , 0.0256  , 0.02048 ],\n",
       "       [0.04    , 0.04    , 0.04    , 0.032   , 0.0256  ],\n",
       "       [0.04    , 0.04    , 0.04    , 0.04    , 0.032   ],\n",
       "       [0.04    , 0.04    , 0.04    , 0.04    , 0.04    ]])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a SxQ (ie, KxK) matrix that describes the likelihood of arriving \n",
    "# at time s and departing at time q\n",
    "LD = tf.einsum('s,sq,q->sq', lmd, mu_v, mu)\n",
    "LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=112, shape=(4, 5, 5), dtype=float64, numpy=\n",
       "array([[[0.04    , 0.032   , 0.0256  , 0.02048 , 0.016384],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      ]],\n",
       "\n",
       "       [[0.      , 0.      , 0.0256  , 0.02048 , 0.016384],\n",
       "        [0.      , 0.      , 0.032   , 0.0256  , 0.02048 ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      ]],\n",
       "\n",
       "       [[0.      , 0.      , 0.      , 0.      , 0.016384],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.      ]],\n",
       "\n",
       "       [[0.      , 0.      , 0.      , 0.      , 0.016384],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.02048 ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.0256  ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.032   ],\n",
       "        [0.      , 0.      , 0.      , 0.      , 0.04    ]]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LD_isq = tf.einsum('sq,isq->isq', LD, i_mask)\n",
    "LD_isq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizing the Beta-Binomial computation\n",
    "\n",
    "Once we know the arrival-departure likelihoods for each user, we move on to vectorize the calculation of the Beta-Binomial likelihood $R_i(s,q)$.\n",
    "\n",
    "We know that \n",
    "\n",
    "###  $R_i(s,q) = f(u_i|n,\\alpha,\\beta) = \\frac{\\Gamma(n+1)}{\\Gamma(u_i+1)\\Gamma(n-u_i+1)} \\frac{\\Gamma(u_i+\\alpha)\\Gamma(n-u_i+\\beta)}{\\Gamma(n+\\alpha+\\beta)}                        \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}$\n",
    "\n",
    "with $n = q-s+1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = q - s + 1\n",
    "d = np.zeros([K,K])\n",
    "for s in range(K):\n",
    "    for q in range(K):\n",
    "        d[s,q] = q-s+1\n",
    "        \n",
    "# n-u\n",
    "# count = list(data['count'].values)\n",
    "n_u = np.zeros([I,K,K])\n",
    "for i in range(len(count)):\n",
    "    n_u[i] = d - count[i]\n",
    "\n",
    "n = tf.constant(np.clip(d,a_min=0,a_max=K+1))\n",
    "n_u = tf.constant(np.clip(n_u,a_min=0,a_max=max(count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=670, shape=(4, 5, 5), dtype=float64, numpy=\n",
       "array([[[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]],\n",
       "\n",
       "       [[2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2.]],\n",
       "\n",
       "       [[5., 5., 5., 5., 5.],\n",
       "        [5., 5., 5., 5., 5.],\n",
       "        [5., 5., 5., 5., 5.],\n",
       "        [5., 5., 5., 5., 5.],\n",
       "        [5., 5., 5., 5., 5.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]]])>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_1d_to_3d(x, K, L):\n",
    "    '''\n",
    "    Takes vector x of dimensionality I and broadcast it, to return a 3d tensor,\n",
    "    I x K x L, where the values of the 2d KxL matrix have the values of x[i]\n",
    "    '''\n",
    "    return tf.einsum(\"i,sq->isq\", x, tf.ones(shape=(K,L), dtype=tf.float64) )\n",
    "\n",
    "transform_1d_to_3d_new(u, K, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=148, shape=(5, 5), dtype=float64, numpy=\n",
       "array([[1., 2., 3., 4., 5.],\n",
       "       [0., 1., 2., 3., 4.],\n",
       "       [0., 0., 1., 2., 3.],\n",
       "       [0., 0., 0., 1., 2.],\n",
       "       [0., 0., 0., 0., 1.]])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=657, shape=(4, 5, 5), dtype=float64, numpy=\n",
       "array([[[1., 2., 3., 4., 5.],\n",
       "        [0., 1., 2., 3., 4.],\n",
       "        [0., 0., 1., 2., 3.],\n",
       "        [0., 0., 0., 1., 2.],\n",
       "        [0., 0., 0., 0., 1.]],\n",
       "\n",
       "       [[1., 2., 3., 4., 5.],\n",
       "        [0., 1., 2., 3., 4.],\n",
       "        [0., 0., 1., 2., 3.],\n",
       "        [0., 0., 0., 1., 2.],\n",
       "        [0., 0., 0., 0., 1.]],\n",
       "\n",
       "       [[1., 2., 3., 4., 5.],\n",
       "        [0., 1., 2., 3., 4.],\n",
       "        [0., 0., 1., 2., 3.],\n",
       "        [0., 0., 0., 1., 2.],\n",
       "        [0., 0., 0., 0., 1.]],\n",
       "\n",
       "       [[1., 2., 3., 4., 5.],\n",
       "        [0., 1., 2., 3., 4.],\n",
       "        [0., 0., 1., 2., 3.],\n",
       "        [0., 0., 0., 1., 2.],\n",
       "        [0., 0., 0., 0., 1.]]])>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_2d_to_3d(xy, Z):\n",
    "    '''\n",
    "    Takes matrix  xy of dimensionality X * Y  and broadcast it Z times, \n",
    "    to return a 3d tensor, Z x X x Y, where the values of the 2d KxL matrix have the values of xy[z]\n",
    "    '''\n",
    "    return tf.einsum(\"xy,z->zxy\", xy, tf.ones(shape=[Z], dtype=tf.float64) )\n",
    "\n",
    "transform_2d_to_3d(n , I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\frac{\\Gamma(n+1)}{\\Gamma(u_i+1)\\Gamma(n-u_i+1)} \\frac{\\Gamma(u_i+\\alpha)\\Gamma(n-u_i+\\beta)}{\\Gamma(n+\\alpha+\\beta)}                        \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the log of the value above, as Tensorflow does not \n",
    "# have Gamma function implemented directly but it has lgamma \n",
    "# Matrix of shape I x K (s=0..K-1)  x K (q=0..K-1)  \n",
    "\n",
    "# tf.lgamma(n+1) \n",
    "R_isq = transform_2d_to_3d( tf.lgamma(tf.constant(n+1) ), I)\n",
    "# - tf.lgamma(u+1) \n",
    "R_isq -= transform_1d_to_3d( tf.lgamma(u+1), K, K )\n",
    "# - tf.lgamma(n-u+1)\n",
    "R_isq -= tf.lgamma( tf.constant(n_u) + 1 )   \n",
    "# + tf.lgamma(u+a) \n",
    "R_isq +=  transform_1d_to_3d(tf.lgamma(u+a), K, K)\n",
    "# + tf.lgamma(n-u+b)\n",
    "R_isq +=  tf.lgamma( tf.constant(n_u) + b )\n",
    "# - tf.lgamma(n+a+b)\n",
    "R_isq -= transform_2d_to_3d( tf.lgamma(tf.constant(n) +a+b ), I)\n",
    "# + tf.lgamma(a+b - tf.lgamma(a) -tf.lgamma(b)\n",
    "R_isq += tf.lgamma( a + b ) - tf.lgamma(a) - tf.lgamma(b )\n",
    "\n",
    "# The above is the computation of the log, so we take the exponent\n",
    "R_isq = tf.exp(R_isq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the likelihood, that the worker i, who arrived at time s and departed at time q\n",
    "# also appeared u_i times in our surveys.\n",
    "R_isq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, f ,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_isq[1] # this is the likelihood matrix for the user that appeared twice. \n",
    "# Elements in the diagonal and below (inclusive) are not valid, as they allow for s-q+1 to be 1 and below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_isq[2] # this is the likelihood matrix for the user that appeared five times. \n",
    "# only the element R_isq[2][0][4] is a valid element, as it is the only one where s-q+1 >= 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the likelihood\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LD_isq * R_isq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1518236477811,
     "user": {
      "displayName": "Panos Ipeirotis",
      "photoUrl": "//lh4.googleusercontent.com/-dIWj8iHQSKU/AAAAAAAAAAI/AAAAAAAC_ik/-lah8-gvNJM/s50-c-k-no/photo.jpg",
      "userId": "103666871486129948108"
     },
     "user_tz": 480
    },
    "id": "66DxgtIGClil",
    "outputId": "6d9bce7c-779e-4862-a02d-fc5a923080cc"
   },
   "outputs": [],
   "source": [
    "# We use einsum to calculate the product of LD_isq with R_isq\n",
    "# and then take the sums of likelihoods for different workers,\n",
    "# sum across s and q, and return a vector with I elements\n",
    "Li = tf.einsum('isq,isq->i', LD_isq, R_isq)\n",
    "\n",
    "# Li =  tf.reduce_sum(products)\n",
    "Li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood for the never observed workers:\n",
    "\n",
    "## $L_0 = \\sum_{s=1}^{K} \\sum_{q=s}^K \\lambda_s \\cdot \\left( \\prod_{v=s}^{q-1} \\left( 1 - \\mu_v \\right) \\right) \\cdot \\mu_q \\cdot  \\frac{\\Gamma(n+\\beta)}{\\Gamma(n+\\alpha+\\beta)}             \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\beta)} $\n",
    "\n",
    "### $n=q-s+1$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LD0 = tf.einsum('s,sq,q->sq', lmd, mu_v, mu)\n",
    "LD0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=239, shape=(5, 5), dtype=float64, numpy=\n",
       "array([[1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1.],\n",
       "       [0., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 1.]])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v0 = np.zeros([K,K])\n",
    "for s in np.arange(K):\n",
    "    c1 = np.zeros(s)\n",
    "    c2 = np.ones(K-s) \n",
    "    v0[s]= np.concatenate((c1, c2))\n",
    "v0_mask = tf.constant(v0)\n",
    "v0_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate from the matrix the combinations of s/q that do not appear\n",
    "# in the sum above\n",
    "LD0 = tf.multiply( LD0  , v0_mask )\n",
    "LD0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R0_sq = tf.exp(\n",
    " tf.lgamma(tf.constant(n) + b )-tf.lgamma(tf.constant(n) +a + b )\n",
    "+ tf.lgamma(a + b )-tf.lgamma( b )\n",
    ")\n",
    "R0_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LD0*R0_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do an element-wise product of the three matrices (as they all have the same dimensions)\n",
    "# and then sum all the elements\n",
    "L0 = tf.einsum('sq,sq->', LD0, R0_sq)\n",
    "# L0 = tf.reduce_sum(products0)\n",
    "L0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the optimization objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1518236478378,
     "user": {
      "displayName": "Panos Ipeirotis",
      "photoUrl": "//lh4.googleusercontent.com/-dIWj8iHQSKU/AAAAAAAAAAI/AAAAAAAC_ik/-lah8-gvNJM/s50-c-k-no/photo.jpg",
      "userId": "103666871486129948108"
     },
     "user_tz": 480
    },
    "id": "eN4Y-Q8_Clio",
    "outputId": "8d5dd6c2-b495-4124-ab33-35f0c6d0d4bb"
   },
   "outputs": [],
   "source": [
    "# Once we have the individual likelihoods, we take the sum of their logs\n",
    "# In our case N = I + U (all workers) and N - D = U (unseen workers)\n",
    "# We use that Γ(n+1) = n!  and logGamma(n+1) = log(n!)\n",
    "\n",
    "# We want sum(lambda)=1 and sum(mu)=1\n",
    "obj1 = tf.square(tf.reduce_sum(lmd) - 1) + tf.square(tf.reduce_sum(mu) - 1)\n",
    "\n",
    "# These are the likelihood function\n",
    "obj2 = tf.reduce_sum(tf.log(Li))\n",
    "obj3 = U * tf.log(L0)\n",
    "obj4 = tf.lgamma(I+U+1.0) - tf.lgamma(U+1.0) - tf.lgamma( tf.constant(I, dtype=tf.float64) +1.0)\n",
    "\n",
    "objective = 100000*obj1 - (obj4 + obj2 + obj3) \n",
    "objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UpO3Qg9uCliq"
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(learning_rate=0.01).minimize(objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KK-xQ7lf_DYH"
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "loss = []\n",
    "\n",
    "feed_data = {\n",
    "    f: np.array(data['min']),  \n",
    "    l: np.array(data['max']), \n",
    "    u: np.array(data['count'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, obj_value, a_est, b_est, lmd_est, mu_est, U_est, o1, o2, o3 = sess.run([train_step, \n",
    "                                                               objective, \n",
    "                                                               a, \n",
    "                                                               b, \n",
    "                                                               lmd, \n",
    "                                                               mu, \n",
    "                                                               U,\n",
    "                                                              obj1, obj2, obj3], feed_dict=feed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1, o2, o3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rsqu.eval( feed_dict=feed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68,
     "output_extras": [
      {
       "item_id": 460
      },
      {
       "item_id": 1250
      }
     ]
    },
    "colab_type": "code",
    "id": "IL7zg8Y-Cliu",
    "outputId": "966b8075-01a6-47f6-f14a-2e5d63036701"
   },
   "outputs": [],
   "source": [
    "t = tqdm(range(10000))\n",
    "\n",
    "feed_data = {\n",
    "    f: np.array(data['min']),  \n",
    "    l: np.array(data['max']), \n",
    "    u: np.array(data['count'])\n",
    "}\n",
    "\n",
    "for epoch in t: \n",
    "    _, obj_value, a_est, b_est, lmd_est, mu_est, U_est = sess.run([train_step, objective, a, b, lmd, mu, U], feed_dict=feed_data)\n",
    "    \n",
    "    \n",
    "    avg_lambda = np.mean(lmd_est)\n",
    "    avg_mu = np.mean(mu_est) \n",
    "    std_lambda = np.std(lmd_est)\n",
    "    std_mu = np.std(mu_est)\n",
    "    loss.append( {\"Iteration\": epoch, \"Loss\": obj_value, \"a_est\": a_est, \"b_est\": b_est, \"U\": U_est } )\n",
    "    template = \"{obj:10.3f} / {alpha:6.3f} / {beta:6.3f} / {al:6.3f} / {am:6.3f} / {u:6.3f}\"\n",
    "    if epoch % 100 == 0:\n",
    "        status = template.format(\n",
    "                        obj = obj_value, \n",
    "                        alpha = a_est, \n",
    "                        beta = b_est, \n",
    "                        al = avg_lambda, \n",
    "                        am = avg_mu, \n",
    "                        u = U_est)\n",
    "        t.set_description(status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 296,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 464,
     "status": "ok",
     "timestamp": 1518237817618,
     "user": {
      "displayName": "Panos Ipeirotis",
      "photoUrl": "//lh4.googleusercontent.com/-dIWj8iHQSKU/AAAAAAAAAAI/AAAAAAAC_ik/-lah8-gvNJM/s50-c-k-no/photo.jpg",
      "userId": "103666871486129948108"
     },
     "user_tz": 480
    },
    "id": "k7JPEzyRCliy",
    "outputId": "7fad6df9-0ebc-48f8-ef02-8f7ca3a0f23e"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(loss).set_index('Iteration').Loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Okq7QoX5Cli0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(loss).set_index('Iteration')[ ['a_est','b_est'] ].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(loss).set_index('Iteration')[ ['U'] ].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "8-Likelihood_Tensorflow.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
