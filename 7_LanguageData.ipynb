{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographics API\n",
    "\n",
    "Below we have the code that retrieves the data from the  Mechanical Turk Tracker Demographics API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# This function takes as input the response for a single survey, and transforms it into a flat dictionary\n",
    "def flatten(item):\n",
    "    fmt = \"%Y-%m-%dT%H:%M:%S.%fZ\"\n",
    "    \n",
    "    hit_answer_date = datetime.strptime(item[\"date\"], fmt)\n",
    "    hit_creation_str = item.get(\"hitCreationDate\")\n",
    "    \n",
    "    if hit_creation_str is None: \n",
    "        hit_creation_date = None \n",
    "        diff = None\n",
    "    else:\n",
    "        hit_creation_date = datetime.strptime(hit_creation_str, fmt)\n",
    "        # convert to unix timestamp\n",
    "        hit_date_ts = time.mktime(hit_creation_date.timetuple())\n",
    "        answer_date_ts = time.mktime(hit_answer_date.timetuple())\n",
    "        diff = int(answer_date_ts-hit_date_ts)\n",
    "    \n",
    "    result = {\n",
    "        \"worker_id\": str(item[\"workerId\"]),\n",
    "        \"gender\": str(item[\"answers\"][\"gender\"]).lower(),\n",
    "        \"household_income\": str(item[\"answers\"][\"householdIncome\"]),\n",
    "        \"educational_level\": str(item[\"answers\"].get(\"educationalLevel\")),\n",
    "        \"household_size\": str(item[\"answers\"][\"householdSize\"]),\n",
    "        \"marital_status\": str(item[\"answers\"].get(\"maritalStatus\")),\n",
    "        \"languages_spoken\": str(item[\"answers\"].get(\"languagesSpoken\")),\n",
    "        \"time_spent_on_mturk\": str(item[\"answers\"].get(\"timeSpentOnMturk\")),\n",
    "        \"weekly_income_from_mturk\": str(item[\"answers\"].get(\"weeklyIncomeFromMturk\")),\n",
    "        \"year_of_birth\": int(item[\"answers\"][\"yearOfBirth\"]),\n",
    "        \"location_city\": str(item.get(\"locationCity\")),\n",
    "        \"location_region\": str(item.get(\"locationRegion\")),\n",
    "        \"location_country\": str(item[\"locationCountry\"]),\n",
    "        \"hit_answered_date\": hit_answer_date,\n",
    "        \"hit_creation_date\": hit_creation_date,\n",
    "        \"post_to_completion_secs\": diff\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved  5000  responses\n",
      "Total of  5000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  10000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  15000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  20000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  25000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  30000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  35000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  40000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  45000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  50000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  55000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  60000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  65000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  70000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  75000  responses in our data\n",
      "Something went wrong with the network call\n",
      "Something went wrong with the network call\n",
      "Retrieved  5000  responses\n",
      "Total of  80000  responses in our data\n",
      "Something went wrong with the network call\n",
      "Something went wrong with the network call\n",
      "Retrieved  5000  responses\n",
      "Total of  85000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  90000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  95000  responses in our data\n",
      "Something went wrong with the network call\n",
      "Something went wrong with the network call\n",
      "Something went wrong with the network call\n",
      "Something went wrong with the network call\n",
      "Something went wrong with the network call\n",
      "Retrieved  5000  responses\n",
      "Total of  100000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  105000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  110000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  115000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  120000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  125000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  130000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  135000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  140000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  145000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  150000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  155000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  160000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  165000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  170000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  175000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  180000  responses in our data\n",
      "Retrieved  5000  responses\n",
      "Total of  185000  responses in our data\n",
      "Retrieved  3039  responses\n",
      "Total of  188039  responses in our data\n"
     ]
    }
   ],
   "source": [
    "# The code below retrieves all the responses from the Demographics API\n",
    "# Since we cannot get all the responses at once, we fetch a few thousand\n",
    "# records at a time, until fetching them all\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "limit = 5000\n",
    "\n",
    "# The API call that returns the last survey responses\n",
    "baseurl = \"https://mturk-surveys.appspot.com/\" + \\\n",
    "    \"_ah/api/survey/v1/survey/demographics/answers?limit=\" + str(limit)\n",
    "\n",
    "# This is the cursor variable, used to retrieve more pages of results\n",
    "nextPageToken = None\n",
    "\n",
    "# We store the results in this list\n",
    "results = []\n",
    "\n",
    "while True:\n",
    "    if nextPageToken == None:\n",
    "        url = baseurl\n",
    "    else:\n",
    "        url = baseurl + \"&cursor=\" + nextPageToken\n",
    "\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code == 200:\n",
    "        data = json.loads(resp.text)\n",
    "        items = data.get(\"items\")\n",
    "        if items == None:\n",
    "            break\n",
    "        print(\"Retrieved \", len(items), \" responses\")\n",
    "        responses = [flatten(item) for item in items]\n",
    "        results.extend(responses)\n",
    "        print(\"Total of \", len(results), \" responses in our data\")\n",
    "    else:\n",
    "        print(\"Something went wrong with the network call\")\n",
    "\n",
    "    nextPageToken = data.get(\"nextPageToken\")\n",
    "    if nextPageToken == None:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188039\n"
     ]
    }
   ],
   "source": [
    "# Let's print the total number of retrieved responses\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "# Let's save the file as a CSV\n",
    "df.to_csv(\"mturk_surveys_extended.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English', 'English,Spanish', 'English', ..., 'None', 'None',\n",
       "       'None'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.languages_spoken.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'Abkhazian',\n",
       " 'Afar',\n",
       " 'Afrikaans',\n",
       " 'Albanian',\n",
       " 'Amharic',\n",
       " 'Arabic',\n",
       " 'Armenian',\n",
       " 'Assamese',\n",
       " 'Azerbaijani',\n",
       " 'Bashkir',\n",
       " 'Basque',\n",
       " 'Bengali',\n",
       " 'Bihari',\n",
       " 'Bulgarian',\n",
       " 'Burmese',\n",
       " 'Byelorussian',\n",
       " 'Cambodian',\n",
       " 'Catalan',\n",
       " 'Chinese',\n",
       " 'Croatian',\n",
       " 'Czech',\n",
       " 'Danish',\n",
       " 'Dutch',\n",
       " 'English',\n",
       " 'Esperanto',\n",
       " 'Estonian',\n",
       " 'Fiji',\n",
       " 'Finnish',\n",
       " 'French',\n",
       " 'Frisian',\n",
       " 'Gaelic',\n",
       " 'Galician',\n",
       " 'Georgian',\n",
       " 'German',\n",
       " 'Greek',\n",
       " 'Guarani',\n",
       " 'Gujarati',\n",
       " 'Hausa',\n",
       " 'Hebrew',\n",
       " 'Hindi',\n",
       " 'Hungarian',\n",
       " 'Icelandic',\n",
       " 'Indonesian',\n",
       " 'Interlingua',\n",
       " 'Irish',\n",
       " 'Italian',\n",
       " 'Japanese',\n",
       " 'Javanese',\n",
       " 'Kannada',\n",
       " 'Kashmiri',\n",
       " 'Kazakh',\n",
       " 'Korean',\n",
       " 'Kurdish',\n",
       " 'Laothian',\n",
       " 'Latin',\n",
       " 'Latvian',\n",
       " 'Lithuanian',\n",
       " 'Macedonian',\n",
       " 'Malagasy',\n",
       " 'Malay',\n",
       " 'Malayalam',\n",
       " 'Maltese',\n",
       " 'Marathi',\n",
       " 'Mongolian',\n",
       " 'Nauru',\n",
       " 'Nepali',\n",
       " 'Norwegian',\n",
       " 'Oriya',\n",
       " 'Pashto',\n",
       " 'Persian',\n",
       " 'Polish',\n",
       " 'Portuguese',\n",
       " 'Punjabi',\n",
       " 'Quechua',\n",
       " 'Romanian',\n",
       " 'Russian',\n",
       " 'Samoan',\n",
       " 'Sanskrit',\n",
       " 'Serbian',\n",
       " 'Serbo-Croatian',\n",
       " 'Setswana',\n",
       " 'Shona',\n",
       " 'Sindhi',\n",
       " 'Singhalese',\n",
       " 'Slovak',\n",
       " 'Slovenian',\n",
       " 'Somali',\n",
       " 'Spanish',\n",
       " 'Swahili',\n",
       " 'Swedish',\n",
       " 'Tagalog',\n",
       " 'Tamil',\n",
       " 'Tatar',\n",
       " 'Tegulu',\n",
       " 'Thai',\n",
       " 'Tibetan',\n",
       " 'Turkish',\n",
       " 'Turkmen',\n",
       " 'Ukrainian',\n",
       " 'Urdu',\n",
       " 'Uzbek',\n",
       " 'Vietnamese',\n",
       " 'Welsh',\n",
       " 'Yiddish',\n",
       " 'Yoruba',\n",
       " 'Zulu'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol = [entries.split(',') for entries in df.languages_spoken.values if entries!='None']\n",
    "s = set()\n",
    "for l in lol:\n",
    "    for m in l:\n",
    "        s.add(m)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106972"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_with_language = len([v for v in df.languages_spoken.values if v!='None' and v!=''])\n",
    "people_with_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    136310\n",
       "IN     34084\n",
       "CA      2724\n",
       "GB      1991\n",
       "BR      1498\n",
       "IT      1054\n",
       "DE       716\n",
       "PH       554\n",
       "FR       524\n",
       "ES       504\n",
       "VE       493\n",
       "ZZ       380\n",
       "MX       328\n",
       "AU       291\n",
       "NL       251\n",
       "AE       235\n",
       "KE       220\n",
       "PK       201\n",
       "RO       196\n",
       "JP       179\n",
       "TR       176\n",
       "NG       174\n",
       "RU       161\n",
       "ID       160\n",
       "PT       159\n",
       "TH       159\n",
       "IE       156\n",
       "GR       153\n",
       "MK       140\n",
       "UA       133\n",
       "       ...  \n",
       "ME         2\n",
       "AM         2\n",
       "SR         2\n",
       "DJ         2\n",
       "LI         2\n",
       "PY         2\n",
       "HT         2\n",
       "MV         2\n",
       "SX         2\n",
       "LA         2\n",
       "MO         2\n",
       "AZ         2\n",
       "RW         2\n",
       "TG         1\n",
       "CN         1\n",
       "GM         1\n",
       "BM         1\n",
       "FJ         1\n",
       "BU         1\n",
       "AI         1\n",
       "IM         1\n",
       "NE         1\n",
       "TZ         1\n",
       "CD         1\n",
       "AG         1\n",
       "PS         1\n",
       "PF         1\n",
       "UZ         1\n",
       "GN         1\n",
       "FM         1\n",
       "Name: location_country, Length: 157, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IN    8844\n",
       "US    8341\n",
       "BR    1003\n",
       "IT     654\n",
       "CA     644\n",
       "DE     378\n",
       "ES     315\n",
       "FR     264\n",
       "GB     258\n",
       "VE     165\n",
       "MX     161\n",
       "NL      99\n",
       "RO      77\n",
       "PH      71\n",
       "PT      64\n",
       "KE      54\n",
       "CO      52\n",
       "RU      52\n",
       "GR      48\n",
       "AU      47\n",
       "AE      45\n",
       "JP      44\n",
       "EG      43\n",
       "IE      40\n",
       "MK      40\n",
       "BD      39\n",
       "BG      36\n",
       "BE      36\n",
       "AR      35\n",
       "ID      34\n",
       "      ... \n",
       "ZA       5\n",
       "LK       5\n",
       "SV       5\n",
       "NZ       5\n",
       "CY       4\n",
       "MT       4\n",
       "CH       4\n",
       "SK       4\n",
       "JO       3\n",
       "IQ       3\n",
       "LV       3\n",
       "MD       3\n",
       "NI       3\n",
       "NA       2\n",
       "AL       2\n",
       "MN       2\n",
       "OM       2\n",
       "GE       2\n",
       "CW       2\n",
       "JM       2\n",
       "UG       1\n",
       "BY       1\n",
       "MU       1\n",
       "SR       1\n",
       "MV       1\n",
       "LA       1\n",
       "FM       1\n",
       "UY       1\n",
       "RW       1\n",
       "ME       1\n",
       "Name: location_country, Length: 108, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df [  df.languages_spoken.str.contains(',') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11471"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bilingual and above\n",
    "len(df [ df.languages_spoken.str.contains(',') ].worker_id.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bilingual'] = df.languages_spoken.str.contains(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>bilingual</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>perc_bilingual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location_country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LB</th>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BR</th>\n",
       "      <td>495.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>0.669559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BH</th>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES</th>\n",
       "      <td>189.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IT</th>\n",
       "      <td>400.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>0.620493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DZ</th>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG</th>\n",
       "      <td>34.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.558442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA</th>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.547619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>338.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.527933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>260.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.503817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MN</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RW</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MV</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NI</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MX</th>\n",
       "      <td>167.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.490854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZW</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>61.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.460177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BO</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT</th>\n",
       "      <td>41.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.438356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BG</th>\n",
       "      <td>48.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DO</th>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.425926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>49.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT</th>\n",
       "      <td>95.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.402516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CW</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AG</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BZ</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CM</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HT</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LI</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LC</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KZ</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KN</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KH</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JE</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HN</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LU</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GY</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GU</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PS</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PY</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FJ</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DM</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DJ</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KG</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "bilingual         False    True  perc_bilingual\n",
       "location_country                               \n",
       "FM                  0.0     1.0        1.000000\n",
       "LB                  5.0    18.0        0.782609\n",
       "BR                495.0  1003.0        0.669559\n",
       "BH                 14.0    24.0        0.631579\n",
       "ES                189.0   315.0        0.625000\n",
       "IT                400.0   654.0        0.620493\n",
       "DZ                 17.0    24.0        0.585366\n",
       "EG                 34.0    43.0        0.558442\n",
       "MA                 19.0    23.0        0.547619\n",
       "TN                  8.0     9.0        0.529412\n",
       "DE                338.0   378.0        0.527933\n",
       "FR                260.0   264.0        0.503817\n",
       "ME                  1.0     1.0        0.500000\n",
       "MN                  2.0     2.0        0.500000\n",
       "RW                  1.0     1.0        0.500000\n",
       "SR                  1.0     1.0        0.500000\n",
       "NA                  2.0     2.0        0.500000\n",
       "MV                  1.0     1.0        0.500000\n",
       "LA                  1.0     1.0        0.500000\n",
       "NI                  3.0     3.0        0.500000\n",
       "MX                167.0   161.0        0.490854\n",
       "ZW                 10.0     9.0        0.473684\n",
       "CO                 61.0    52.0        0.460177\n",
       "BO                  6.0     5.0        0.454545\n",
       "LT                 41.0    32.0        0.438356\n",
       "BG                 48.0    36.0        0.428571\n",
       "DO                 31.0    23.0        0.425926\n",
       "AR                 49.0    35.0        0.416667\n",
       "PT                 95.0    64.0        0.402516\n",
       "CW                  3.0     2.0        0.400000\n",
       "...                 ...     ...             ...\n",
       "AG                  1.0     0.0        0.000000\n",
       "BZ                 42.0     0.0        0.000000\n",
       "CN                  1.0     0.0        0.000000\n",
       "CM                 11.0     0.0        0.000000\n",
       "HT                  2.0     0.0        0.000000\n",
       "LI                  2.0     0.0        0.000000\n",
       "LC                  9.0     0.0        0.000000\n",
       "NE                  1.0     0.0        0.000000\n",
       "KZ                  3.0     0.0        0.000000\n",
       "KN                  7.0     0.0        0.000000\n",
       "KH                 19.0     0.0        0.000000\n",
       "AF                  8.0     0.0        0.000000\n",
       "JE                  3.0     0.0        0.000000\n",
       "IS                  8.0     0.0        0.000000\n",
       "IM                  1.0     0.0        0.000000\n",
       "PF                  1.0     0.0        0.000000\n",
       "HN                 36.0     0.0        0.000000\n",
       "LU                 12.0     0.0        0.000000\n",
       "GY                  8.0     0.0        0.000000\n",
       "GU                  4.0     0.0        0.000000\n",
       "PS                  1.0     0.0        0.000000\n",
       "GN                  1.0     0.0        0.000000\n",
       "PY                  2.0     0.0        0.000000\n",
       "GM                  1.0     0.0        0.000000\n",
       "GD                  5.0     0.0        0.000000\n",
       "FJ                  1.0     0.0        0.000000\n",
       "ET                  4.0     0.0        0.000000\n",
       "DM                 18.0     0.0        0.000000\n",
       "DJ                  2.0     0.0        0.000000\n",
       "KG                  4.0     0.0        0.000000\n",
       "\n",
       "[157 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pv_bilingual = df.pivot_table(\n",
    "    index = 'location_country',\n",
    "    columns='bilingual',\n",
    "    values = 'worker_id',\n",
    "    aggfunc='count'\n",
    ").fillna(0)\n",
    "\n",
    "pv_bilingual['perc_bilingual'] = pv_bilingual[True] / (pv_bilingual[True] + pv_bilingual[False])\n",
    "pv_bilingual.sort_values('perc_bilingual', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51463"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique ids of workers that answered the language question\n",
    "len(df [ df.languages_spoken !='None' ].worker_id.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    75045\n",
       "IN    18652\n",
       "CA     1786\n",
       "GB     1397\n",
       "BR     1117\n",
       "IT      708\n",
       "DE      457\n",
       "ES      346\n",
       "FR      276\n",
       "PH      260\n",
       "VE      241\n",
       "ZZ      213\n",
       "MX      190\n",
       "NL      174\n",
       "AU      172\n",
       "KE      144\n",
       "PK      141\n",
       "AE      107\n",
       "IE       95\n",
       "NG       95\n",
       "JP       92\n",
       "RO       92\n",
       "UA       85\n",
       "TH       82\n",
       "PT       77\n",
       "ID       76\n",
       "CO       65\n",
       "RU       62\n",
       "BD       62\n",
       "TR       60\n",
       "      ...  \n",
       "GD        2\n",
       "ET        2\n",
       "KG        2\n",
       "RW        2\n",
       "CM        2\n",
       "LU        2\n",
       "JE        2\n",
       "AL        2\n",
       "ME        2\n",
       "BS        2\n",
       "TJ        2\n",
       "GY        2\n",
       "SX        2\n",
       "UY        2\n",
       "ZM        2\n",
       "MO        1\n",
       "SR        1\n",
       "AM        1\n",
       "KN        1\n",
       "MU        1\n",
       "BN        1\n",
       "TG        1\n",
       "LA        1\n",
       "HT        1\n",
       "UZ        1\n",
       "MV        1\n",
       "FM        1\n",
       "DJ        1\n",
       "GN        1\n",
       "NE        1\n",
       "Name: location_country, Length: 139, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df [  df.languages_spoken.str.contains('English') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df [  df.languages_spoken.str.contains('Tamil') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [  df.languages_spoken.str.contains('Spanish') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [  df.languages_spoken.str.contains('Hindi') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [  df.languages_spoken.str.contains('French') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [  df.languages_spoken.str.contains('Malayalam') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [  df.languages_spoken.str.contains('Tegulu') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [  df.languages_spoken.str.contains('German') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df [  df.languages_spoken.str.contains('Chinese') ].location_country.value_counts() / df.location_country.value_counts()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df [  df.languages_spoken.str.contains('Macedonian') ].location_country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = set([l for v in df.languages_spoken.values if v!='None' \n",
    "                 for l in v.split(',') if l!=''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = []\n",
    "for language in languages:\n",
    "    people = len(set(df[ df.languages_spoken.str.contains(language) ].worker_id.values))\n",
    "    result.append({\"lang\":language, \"unique_workers\": people})\n",
    "    \n",
    "\n",
    "df_cnt = pd.DataFrame(result).sort_values('unique_workers', ascending=False)    \n",
    "print (df_cnt)    \n",
    "# more than 10 people for the language\n",
    "\n",
    "#df2 = pd.DataFrame(result).sort_values('unique_workers', ascending=False)\n",
    "#enough = df2 [df2.unique_workers > 9]\n",
    "#len(enough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnt.unique_workers.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([v for v in df.languages_spoken.values if 'Spanish' in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1189 / 19268 * 170000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(a, b):\n",
    "    \"\"\" return the intersection of two lists \"\"\"\n",
    "    return list(set(a) & set(b))\n",
    "\n",
    "my_langauge = ['English', 'Tamil', 'Spanish', 'Hindi', 'Malayalam', 'French', 'Telugu', 'Chinese', 'German', 'Kannada', 'Italian', 'Portuguese', 'Marathi', 'Arabic', 'Russian', 'Japanese', 'Gujarati', 'Urdu', 'Bengali', 'Punjabi', 'Korean', 'Tagalog', 'Romanian', 'Vietnamese', 'Greek', 'Polish', 'Dutch', 'Turkish', 'Hebrew', 'Swedish', 'Serbian', 'Nepali', 'Bulgarian', 'Macedonian', 'Oriya']\n",
    "pavlick_langauge = ['English', 'Tamil', 'Malayalam', 'Hindi', 'Spanish', 'Telugu', 'Chinese', 'Romanian', 'Portuguese', 'Arabic', 'Kannada', 'German', 'French', 'Polish', 'Urdu', 'Tagalog', 'Marathi', 'Russian', 'Italian', 'Bengali', 'Gujarati', 'Hebrew', 'Dutch', 'Turkish', 'Vietnamese', 'Macedonian', 'Cebuano', 'Swedish', 'Bulgarian', 'Swahili', 'Hungarian', 'Catalan', 'Thai', 'Lithuanian', 'Punjabi']\n",
    "\n",
    "intersect_language = intersect(my_langauge, pavlick_langauge)\n",
    "len(intersect_language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr(my_langauge,pavlick_langauge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
